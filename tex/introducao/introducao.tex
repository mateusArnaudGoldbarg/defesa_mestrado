\section{Introdução}
\begin{frame}{Contextualização e Motivação}
    \begin{flushleft}
	\begin{itemize}
	
	    \item A Inteligência Artificial (IA), já está presente em uma gama de atividades como publicidade, finanças, jogos eletrônicos, visão computacional e diagnósticos médicos;
        \item Técnicas de aprendizado profundo (deep learning) têm sido usados com sucesso na solução de muitos problemas;
        \item A grande quantidade de operações numéricas realizadas em algorítmos de aprendizado profundo podem ser um gargalo quando se é necessário o processamento de um conjunto de dados em um pequeno intervalo de tempo ou quando os recursos de processamento são limitados;
        \item Devido a complexidade das redes neurais profundas, é necessário um elevado espaço em memória para armazena-las.
    \end{itemize}
    \end{flushleft}
\end{frame}

\begin{frame}{Contextualização e Motivação}
    \begin{flushleft}
    	\begin{itemize}
	
	    \item A compressão das Redes Neurais Profundas é uma estratégia viável para a redução da complexidade e aceleração desses algoritmos;
        \item As abordagens mais convencionais de compressão de DNNs são as de poda e de quantização. O desafio é reduzir os modelos de forma a afetar minimamente a acurácia dos modelos.
    \end{itemize}
    \end{flushleft}
\end{frame}


\begin{frame}{Objetivos}
	\begin{itemize}
        \item Desenvolver ténicas de compressão consciente de DNNs utilizando as estratégias de poda, quantização e poda seguida de quantização.
        \item Validar a compressão do modelo de DNNs através das métricas de esparsidade e do tamanho do modelo comprimido em relação ao não comprimido.
        \item Validar a estratégia de compressão consciente de modelos de DNNs aplicando-os à ambientes de microserviços e avaliar sua escalabilidade.
    \end{itemize}
\end{frame}
