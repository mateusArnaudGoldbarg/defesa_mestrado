@Conference{fernandes2021,
  author       = {Fernandes, Marcelo A. C. and Kung, H. T.},
  title        = {A Novel Training Strategy for Deep Learning Model Compression Applied to Viral Classifications},
  booktitle    = "",
  year         = {2021},
  editor       = "",
  volume       = "",
  number       = "",
  series       = "",
  pages        = "",
  month        = "",
  address      = "",
  organization = {IEEE International Joint Conference on Neural Networks (IJCNN)},
  publisher    = "",
  note         = "",
  annote       = ""
}

@electronic{nvidea2015,
  Author = "",
  Date-Added = {2015-10-01},
  Date-Modified = {2016-02-15},
  Keywords = "",
  Lastchecked = {15 jul. 2021},
  Note = {Acesso em: 10 jul. 2021},
  Organization = {nvidia},
  Title = {GPU-Based Deep Learning Inference: A Performance and Power Analysis},
  Url =
  {https://www.nvidia.com/content/tegra/embedded-systems/pdf/jetson_tx1_whitepaper.pdf},
  Urldate = {7 set. 2021},
  Year = {2015}
}

@electronic{blalock2020,
  Author = {Blalock, D. and Ortiz, J. J. G. and Frankle, J. and Guttag, J.},
  Date-Added = "",
  Date-Modified = "",
  Keywords = "",
  Lastchecked = "",
  Note = {Acesso em: 8 jul. 2021},
  Organization = {Cornell University},
  Title = {What is the state of neural network pruning?},
  Url =
  {https://arxiv.org/abs/2003.03033},
  Urldate = "",
  Year = {2020}
}

@electronic{yang2017,
  Author = {Yang, T. and Chen, Y. and Vivienne, S.},
  Date-Added = "",
  Date-Modified = "",
  Keywords = "",
  Lastchecked = "",
  Note = {Acesso em: 9 jul. 2021},
  Organization = {Cornell University},
  Title = {Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning},
  Url =
  {https://arxiv.org/abs/1611.05128},
  Urldate = "",
  Year = {2017}
}

@inproceedings{Quantization1,
  title={Haq: Hardware-aware automated quantization with mixed precision},
  author={Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8612--8620},
  year={2019}
}

@article{Quantization2,
  title={Defend deep neural networks against adversarial examples via fixed and dynamic quantized activation functions},
  author={Rakin, Adnan Siraj and Yi, Jinfeng and Gong, Boqing and Fan, Deliang},
  journal={arXiv preprint arXiv:1807.06714},
  year={2018}
}


@ARTICLE{PruneQuantization1,
  author={Tung, Frederick and Mori, Greg},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Deep Neural Network Compression by In-Parallel Pruning-Quantization}, 
  year={2020},
  volume={42},
  number={3},
  pages={568-579},
  doi={10.1109/TPAMI.2018.2886192}
  }

@INPROCEEDINGS{Quantization4,
  author={W. {Zhe} and J. {Lin} and V. {Chandrasekhar} and B. {Girod}},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Optimizing the Bit Allocation for Compression of Weights and Activations of Deep Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={3826-3830},}